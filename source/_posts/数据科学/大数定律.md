---
title: 大数定律
date: 2018-11-05 16:48:05
tags: [概率]
categories: [数据科学]
---
大数定律分为弱大数定律和强大数定律。强、弱大数定律都是在说：随着样本数的增大，用样本的平均数来估计总体的平均数，是靠谱的。

## 大数定律的条件
 强、弱大数定律的前提条件一样：要求独立同分布i.i.d的随机序列，要求其期望存在。
## 什么是强、弱大数定律
弱大数定律比较早被证明出来，弱大数定律表示样本均值“依概率收敛”于总体均值；而强大数定律是比较晚被证明出来的，它证明了样本均值可以“以概率为1收敛”于总体均值。简单的来说，就是数学家先证明了弱大数定律，后来在没有改变前提的情况下把弱大数定律推进了一步，得到了更厉害的强大数定律。
## 强、弱大数据定律的区别
弱、强大数定律的区别在于，前者是“依概率收敛(convergence in probability)”，后者是“几乎确定收敛(almost surely convergence)或以概率为1收敛、几乎处处收敛”。后者比前者强，满足后者的必定满足前者，而满足前者的未必满足后者。
*  依概率收敛的例子：考虑下图，图中的每条线都代表一个数列，虚线表示一个非常小的区间。总的来说每个数列都越来越趋近0，且大部分时候不会超过虚线所表示的小边界，但是，偶尔会有一两条线超过虚线、然后再回到虚线之内。而且我们不能保证，有没有哪一个数列会在未来再次超出虚线的范围然后再回来——虽然概率很小。注意虚线的范围可以是任意小的实数，此图中大约是，可以把这个边界缩小到，甚至，随你喜欢，这个性质始终存在。
![](https://pic2.zhimg.com/80/4fa791cc554a7ed57cc8ae195e14a3f1_hd.jpg)
*  几乎处处收敛的例子：图中的黑线表示一个随机数列，这个数列在大约n=200之后进入了一个我们定的小边界（用虚线表示），之后我们可以确定，它再也不会超出虚线所表示的边界（超出这个边界的概率是0）。跟上面的例子一样，虚线所表示的边界可以定得任意小，而一定会有一个n值，当这个数列超过了n值之后，超出这个边界的概率就是0了。
![](https://pic2.zhimg.com/80/797cf511cab76d6911718302632691a1_hd.jpg)

内容来源：https://www.zhihu.com/question/21110761 ,作者：runze Zheng
