<!DOCTYPE HTML>
<html lang="zh-CN">
<head>
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="数大招疯">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <link rel="dns-prefetch" href="http://yoursite.com">
    <!--SEO-->





<meta name="robots" content="all" />
<meta name="google" content="all" />
<meta name="googlebot" content="all" />
<meta name="verify" content="all" />
    <!--Title-->


<title>让Spark Streaming在YARN上长时间运行 | 数大招疯</title>


    <link rel="alternate" href="/atom.xml" title="数大招疯" type="application/atom+xml">


    <link rel="icon" href="img/avatar.jpg">

    



<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7">
<link rel="stylesheet" href="/css/font-awesome.min.css?rev=4.5.0">
<link rel="stylesheet" href="/css/style.css?rev=@@hash">




    
	<div class="hide">
		<script type="text/javascript">
			var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan class='cnzz_stat_icon_1263868967 hide' %3E%3Cscript%20src%3D%22https%3A%2F%2Fs95.cnzz.com%2Fz_stat.php%3Fweb_id%3D1272564536%22%3E%3C%2Fscript%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s19.cnzz.com/z_stat.php%3Fid%3D1263868967%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));
		</script>
	</div>






    

</head>


<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<body>
    <header class="main-header"  style="background-image:url(https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1536170179765&amp;di=ab07d5f5a24a9d2bab9d1473a74e006c&amp;imgtype=0&amp;src=http%3A%2F%2Fpic.90sjimg.com%2Fback_pic%2F00%2F04%2F20%2F33%2F9e0ba3e5c577b49250f84a20a11f079c.jpg)"  >
    <div class="main-header-box">
        <a class="header-avatar" href="/" title='XueMin Zhang'>
            <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block">
        </a>
        <div class="branding">
        	<!--<h2 class="text-hide">Snippet主题,从未如此简单有趣</h2>-->
            
                <h2> 数大招疯 </h2>
            
    	</div>
    </div>
</header>

    <nav class="main-navigation">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                    <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="navbar-brand" href="http://yoursite.com">数大招疯</a>
                </div>
                <div class="collapse navbar-collapse" id="main-menu">
                    <ul class="menu">
                        
                            <li role="presentation" class="text-center" >
                                <a href="/"><i class="fa "></i>首页 </a>
                            </li>
                        
                            <li role="presentation" class="text-center" >
                                <a href="/categories/编程基础/"><i class="fa "></i>编程基础 </a>
                            </li>
                        
                            <li role="presentation" class="text-center" >
                                <a href="/categories/大数据/"><i class="fa "></i>大数据 </a>
                            </li>
                        
                            <li role="presentation" class="text-center" >
                                <a href="/categories/数据科学"><i class="fa "></i>数据科学 </a>
                            </li>
                        
                            <li role="presentation" class="text-center" >
                                <a href="/categories/图存储、计算"><i class="fa "></i>图存储、计算 </a>
                            </li>
                        
                            <li role="presentation" class="text-center" >
                                <a href="/categories/工程、工具"><i class="fa "></i>工程、工具 </a>
                            </li>
                        
                            <li role="presentation" class="text-center" >
                                <a href="/categories/"><i class="fa "></i>读书 </a>
                            </li>
                        
                            <li role="presentation" class="text-center" >
                                <a href="/archives/"><i class="fa "></i>时间轴 </a>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>

    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="让Spark Streaming在YARN上长时间运行">
            
	            让Spark Streaming在YARN上长时间运行
            
        </h1>
        <div class="post-meta">

    
    

    <span class="categories-meta fa-wrap">
        <i class="fa fa-folder-open-o"></i>
        <a href="/categories/大数据">
            大数据
        </a>
    </span>
    

    
    <span class="fa-wrap">
        <i class="fa fa-tags"></i>
        <span class="tags-meta">
            
                
                    <a href="/tags/Spark" title='Spark'>
                        Spark
                    </a>
                
            
        </span>
    </span>
    


        <span>
         
         🕒 2018年05月16日
        </span>

       <span>
         <i class="fa fa-icon-user"></i>
          ✍ ZhangXueMin
        </span>

    
        

        
    
</div>

            
            
    </div>
    
    <div class="post-body post-content">
        <p>对于长时间运行的Spark Streaming作业，一旦提交到YARN群集便需要永久运行，直到有意停止。任何中断都会引起严重的处理延迟，并可能导致数据丢失或重复。YARN和Apache Spark都不是为了执行长时间运行的服务而设计的。但是，它们已经成功地满足了近实时数据处理作业的常驻需求。成功并不一定意味着没有技术挑战。</p>
<p>这篇博客总结了在安全的YARN集群上，运行一个关键任务且长时间的Spark Streaming作业的经验。您将学习如何将Spark Streaming应用程序提交到YARN群集，以避免在值班时候的不眠之夜。</p>
<h4 id="Fault-tolerance"><a href="#Fault-tolerance" class="headerlink" title="Fault tolerance"></a>Fault tolerance</h4><p>在YARN集群模式下，Spark驱动程序与Application Master（应用程序分配的第一个YARN容器）在同一容器中运行。此过程负责从YARN 驱动应用程序和请求资源（Spark执行程序）。重要的是，Application Master消除了在应用程序生命周期中运行的任何其他进程的需要。即使一个提交Spark Streaming作业的边缘Hadoop节点失败，应用程序也不会受到影响。</p>
<p>要以集群模式运行Spark Streaming应用程序，请确保为spark-submit命令提供以下参数：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --master yarn --deploy-mode cluster</span><br></pre></td></tr></table></figure></p>
<p>由于Spark驱动程序和Application Master共享一个JVM，Spark驱动程序中的任何错误都会阻止我们长期运行的工作。幸运的是，可以配置重新运行应用程序的最大尝试次数。设置比默认值2更高的值是合理的（从YARN集群属性yarn.resourcemanager.am.max尝试中导出）。对我来说，4工作相当好，即使失败的原因是永久性的，较高的值也可能导致不必要的重新启动。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --master yarn --deploy-mode cluster --conf spark.yarn.maxAppAttempts=4</span><br></pre></td></tr></table></figure></p>
<p>如果应用程序运行数天或数周，而不重新启动或重新部署在高度使用的群集上，则可能在几个小时内耗尽4次尝试。为了避免这种情况，尝试计数器应该在每个小时都重置。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --master yarn --deploy-mode cluster --conf spark.yarn.maxAppAttempts=4  --conf spark.yarn.am.attemptFailuresValidityInterval=1h</span><br></pre></td></tr></table></figure></p>
<p>另一个重要的设置是在应用程序发生故障之前executor失败的最大数量。默认情况下是max（2 * num executors，3），非常适合批处理作业，但不适用于长时间运行的作业。该属性具有相应的有效期间，也应设置。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --master yarn --deploy-mode cluster --conf spark.yarn.maxAppAttempts=4  --conf spark.yarn.am.attemptFailuresValidityInterval=1h --conf spark.yarn.max.executor.failures=&#123;8 * num_executors&#125; --conf spark.yarn.executor.failuresValidityInterval=1h</span><br></pre></td></tr></table></figure></p>
<p>对于长时间运行的作业，您也可以考虑在放弃作业之前提高任务失败的最大数量。默认情况下，任务将重试4次，然后作业失败。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --master yarn --deploy-mode cluster --conf spark.yarn.maxAppAttempts=4  --conf spark.yarn.am.attemptFailuresValidityInterval=1h --conf spark.yarn.max.executor.failures=&#123;8 * num_executors&#125; --conf spark.yarn.executor.failuresValidityInterval=1h --conf spark.task.maxFailures=8</span><br><span class="line">Performance</span><br></pre></td></tr></table></figure></p>
<p>当Spark Streaming应用程序提交到集群时，必须定义运行作业的YARN队列。我强烈建议使用YARN Capacity Scheduler并将长时间运行的作业提交到单独的队列。没有一个单独的YARN队列，您的长时间运行的工作迟早将被的大量Hive查询抢占。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --master yarn --deploy-mode cluster --conf spark.yarn.maxAppAttempts=4  --conf spark.yarn.am.attemptFailuresValidityInterval=1h --conf spark.yarn.max.executor.failures=&#123;8 * num_executors&#125; --conf spark.yarn.executor.failuresValidityInterval=1h --conf spark.task.maxFailures=8  --queue realtime_queue</span><br></pre></td></tr></table></figure></p>
<p>Spark Streaming工作的另一个重要问题是保持处理时间的稳定性和高度可预测性。处理时间应保持在批次持续时间以下以避免延误。我发现Spark的推测执行有很多帮助，特别是在繁忙的群集中。当启用推测性执行时，批处理时间更加稳定。只有当Spark操作是幂等时，才能启用推测模式。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --master yarn --deploy-mode cluster --conf spark.yarn.maxAppAttempts=4  --conf spark.yarn.am.attemptFailuresValidityInterval=1h --conf spark.yarn.max.executor.failures=&#123;8 * num_executors&#125; --conf spark.yarn.executor.failuresValidityInterval=1h --conf spark.task.maxFailures=8  --queue realtime_queue --conf spark.speculation=true</span><br></pre></td></tr></table></figure></p>
<h4 id="Security"><a href="#Security" class="headerlink" title="Security"></a>Security</h4><p>在安全的HDFS群集上，长时间运行的Spark Streaming作业由于Kerberos票据到期而失败。没有其他设置，当Spark Streaming作业提交到集群时，会发布Kerberos票证。当票证到期时Spark Streaming作业不能再从HDFS写入或读取数据。</p>
<p>在理论上（基于文档），应该将Kerberos主体和keytab作为spark-submit命令传递：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --master yarn --deploy-mode cluster --conf spark.yarn.maxAppAttempts=4  --conf spark.yarn.am.attemptFailuresValidityInterval=1h --conf spark.yarn.max.executor.failures=&#123;8 * num_executors&#125; --conf spark.yarn.executor.failuresValidityInterval=1h --conf spark.task.maxFailures=8  --queue realtime_queue --conf spark.speculation=true  --principal user/hostname@domain --keytab /path/to/foo.keytab</span><br></pre></td></tr></table></figure></p>
<p>实际上，由于几个错误（HDFS-9276, SPARK-11182）必须禁用HDFS缓存。如果没有，Spark将无法从HDFS上的文件读取更新的令牌。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --master yarn --deploy-mode cluster --conf spark.yarn.maxAppAttempts=4  --conf spark.yarn.am.attemptFailuresValidityInterval=1h --conf spark.yarn.max.executor.failures=&#123;8 * num_executors&#125; --conf spark.yarn.executor.failuresValidityInterval=1h --conf spark.task.maxFailures=8  --queue realtime_queue --conf spark.speculation=true  --principal user/hostname@domain --keytab /path/to/foo.keytab --conf spark.hadoop.fs.hdfs.impl.disable.cache=true</span><br></pre></td></tr></table></figure></p>
<p>Mark Grover指出，这些错误只影响在HA模式下配置了NameNodes的HDFS集群。谢谢，Mark。</p>
<h4 id="Logging"><a href="#Logging" class="headerlink" title="Logging"></a>Logging</h4><p>访问Spark应用程序日志的最简单方法是配置Log4j控制台追加程序，等待应用程序终止并使用yarn logs -applicationId [applicationId]命令。不幸的是终止长时间运行的Spark Streaming作业来访问日志是不可行的。</p>
<p>我建议安装和配置Elastic，Logstash和Kibana（ELK套装）。ELK的安装和配置是超出了这篇博客的范围，但请记住记录以下上下文字段：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">YARN application id</span><br><span class="line">YARN container hostname</span><br><span class="line">Executor id (Spark driver is always 000001, Spark executors start from 000002)</span><br><span class="line">YARN attempt (to check how many times Spark driver has been restarted)</span><br></pre></td></tr></table></figure></p>
<p>Log4j配置使用Logstash特定的appender和布局定义应该传递给spark-submit命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-submit --master yarn --deploy-mode cluster --conf spark.yarn.maxAppAttempts=4  --conf spark.yarn.am.attemptFailuresValidityInterval=1h --conf spark.yarn.max.executor.failures=&#123;8 * num_executors&#125; --conf spark.yarn.executor.failuresValidityInterval=1h --conf spark.task.maxFailures=8  --queue realtime_queue --conf spark.speculation=true  --principal user/hostname@domain --keytab /path/to/foo.keytab --conf spark.hadoop.fs.hdfs.impl.disable.cache=true  --conf spark.driver.extraJavaOptions=-Dlog4j.configuration=file:log4j.properties --conf spark.executor.extraJavaOptions=-Dlog4j.configuration=file:log4j.properties --files /path/to/log4j.properties</span><br></pre></td></tr></table></figure></p>
<p>最后，Spark Job的Kibana仪表板可能如下所示：</p>
<h4 id="Monitoring"><a href="#Monitoring" class="headerlink" title="Monitoring"></a>Monitoring</h4><p>长时间运行的工作全天候运行，所以了解历史指标很重要。Spark UI仅在有限数量的批次中保留统计信息，并且在重新启动后，所有度量标准都消失了。再次，需要外部工具。我建议安装Graphite用于收集指标和Grafana来建立仪表板。</p>
<p>首先，Spark需要配置为将指标报告给Graphite，准备metrics.properties文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">*.sink.graphite.class=org.apache.spark.metrics.sink.GraphiteSink</span><br><span class="line">*.sink.graphite.host=[hostname]</span><br><span class="line">*.sink.graphite.port=[port] *.sink.graphite.prefix=some_meaningful_name</span><br><span class="line"></span><br><span class="line">driver.source.jvm.class=org.apache.spark.metrics.source.JvmSource</span><br><span class="line">executor.source.jvm.class=org.apache.spark.metrics.source.JvmSource</span><br></pre></td></tr></table></figure></p>
<h4 id="Graceful-stop"><a href="#Graceful-stop" class="headerlink" title="Graceful stop"></a>Graceful stop</h4><p>最后一个难题是如何以优雅的方式停止部署在YARN上的Spark Streaming应用程序。停止（甚至杀死）YARN应用程序的标准方法是使用命令yarn application -kill [applicationId]。这个命令会停止Spark Streaming应用程序，但这可能发生在批处理中。因此，如果该作业是从Kafka读取数据然后在HDFS上保存处理结果，并最终提交Kafka偏移量，当作业在提交偏移之前停止工作时，您应该预见到HDFS会有重复的数据。</p>
<p>解决优雅关机问题的第一个尝试是在关闭程序时回调Spark Streaming Context的停止方法。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sys.addShutdownHook &#123;</span><br><span class="line">    streamingContext.stop(stopSparkContext = true, stopGracefully = true)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>令人失望的是，由于Spark应用程序几乎立即被杀死，一个退出回调函数来不及完成已启动的批处理任务。此外，不能保证JVM会调用shutdown hook。</p>
<p>在撰写本博客文章时，唯一确认的YARN Spark Streaming应用程序的确切方法是通知应用程序关于计划关闭，然后以编程方式停止流式传输（但不是关闭挂钩）。命令yarn application -kill 如果通知应用程序在定义的超时后没有停止，则应该仅用作最后手段。</p>
<p>可以使用HDFS上的标记文件（最简单的方法）或使用驱动程序上公开的简单Socket / HTTP端点（复杂方式）通知应用程序。</p>
<p>因为我喜欢KISS原理，下面你可以找到shell脚本伪代码，用于启动/停止Spark Streaming应用程序使用标记文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">start() &#123;</span><br><span class="line">    hdfs dfs -touchz /path/to/marker/my_job_unique_name</span><br><span class="line">    spark-submit ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">stop() &#123;</span><br><span class="line">    hdfs dfs -rm /path/to/marker/my_job_unique_name</span><br><span class="line">    force_kill=true application_id=$(yarn application -list | grep -oe &quot;application_[0-9]*_[0-9]*&quot;`) for i in `seq 1 10`; do application_status=$(yarn application -status $&#123;application_id&#125; | grep &quot;State : \(RUNNING\|ACCEPTED\)&quot;) if [ -n &quot;$application_status&quot; ]; then</span><br><span class="line">            sleep 60s else force_kill=false</span><br><span class="line">            break fi</span><br><span class="line">    done</span><br><span class="line">    $force_kill &amp;&amp; yarn application -kill $&#123;application_id&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>在Spark Streaming应用程序中，后台线程应该监视标记文件，当文件消失时停止上下文调用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">streamingContext.stop(stopSparkContext = true, stopGracefully = true)</span><br></pre></td></tr></table></figure></p>
<h4 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h4><p>可以看到，部署在YARN上的关键任务Spark Streaming应用程序的配置相当复杂。以上提出的技术，由一些非常聪明的开发人员经过漫长而冗长乏味的迭代学习。最终，部署在高可用的YARN集群上的长期运行的Spark Streaming应用非常稳定。</p>
<p>翻译：<a href="http://mkuthan.github.io/blog/2016/09/30/spark-streaming-on-yarn/" target="_blank" rel="noopener">http://mkuthan.github.io/blog/2016/09/30/spark-streaming-on-yarn/</a></p>

    </div>

    <div class="post-footer">
        <div>
            
                声明：欢迎转载、重新发布。如用于商业目的，请<a href="mailto:xuemin.zhang@foxmail.com" target="_blank">联系作者</a>获得授权。非商业目的，请务必保留文章作者署名(<a href="https://zhangxuemin.cn" target="_blank">张学敏</a>)及链接(https://zhangxuemin.cn)。
            
        </div>
        <div>
            
        </div>
    </div>
</article>

<div class="article-nav prev-next-wrap clearfix">
    
    
        <a href="/2018/04/29/大数据/Spark/开启Back Pressure使生产环境的Spark Streaming应用更稳定、有效/" class="next-post btn btn-default" title='开启Back Pressure使生产环境的Spark Streaming应用更稳定、有效'>
            <span class="hidden-lg">下一篇</span>
            <span class="hidden-xs">开启Back Pressure使生产环境的Spark Streaming应用更稳定、有效</span><i class="fa fa-angle-right fa-fw"></i>
        </a>
    
</div>


    <div id="comments">
        
    
    <div id="vcomments" class="valine"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="/assets/valine.min.js"></script>

    <script>
        new Valine({
            av: AV,
            el: '#vcomments',
            appId: 'Wf244rKqAfDvqO3ID8IMPpHC-gzGzoHsz',
            appKey: 'a3FFMqGAk68xa9qyPfw0Cw6N',
            placeholder: '发表评论',
            notify: false,
            verify: false,
            avatar: 'mm',
            meta: 'nick,mail'.split(','),
            pageSize: '10',
            path: window.location.pathname,
            lang: 'zh-CN'.toLowerCase()
        })
    </script>


    </div>





                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">文章目录</h3>
        
            <ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#Fault-tolerance"><span class="toc-text">Fault tolerance</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Security"><span class="toc-text">Security</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Logging"><span class="toc-text">Logging</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Monitoring"><span class="toc-text">Monitoring</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Graceful-stop"><span class="toc-text">Graceful stop</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Summary"><span class="toc-text">Summary</span></a></li></ol>
        
    </div>
</aside>

                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>

<a id="back-to-top" class="icon-btn hide">
	<i class="fa fa-chevron-up"></i>
</a>




    <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<div class="copyright">
    <div class="container">
    

        Since<span>2015 | <span>ZhangXueMin</span> | <span class="post-meta-item-icon"><i class="fa fa-area-chart"></i></span>总访问量<span id="busuanzi_value_site_pv"></span>次
    </div>
</div>







<script src="/js/app.js?rev=@@hash"></script>

</body>
</html>